Logging to ./logs/first_run_6
<stable_baselines3.ppo.ppo.PPO object at 0x7f9bc1cc8850>
50000
<__main__.SummaryWriterCallback object at 0x7f9bc1cc8cd0>
1
first_run
True
False
0
<stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f9bc1cc8910>
<stable_baselines3.common.buffers.RolloutBuffer object at 0x7f9bc1cc89d0>
2048
99
tensor([[-0.1714,  0.6848,  0.1904,  ...,  0.3432,  0.9259, -0.1579]],
       device='cuda:0')
[[ 0.07906201  1.3362937  -0.08293784 -2.1416235   0.7791417   1.1191127
   1.3856162   0.27537555  0.79398644  0.5335053   1.4077309   0.36317116
  -0.6226528  -0.03318336  0.7976863  -1.7284023   1.7969772  -0.25947368
  -0.92329156  0.36749226 -1.4509255   0.6012655  -0.33593607  1.3409042
   0.17069107 -0.8102963   0.61052924  1.3223542  -1.5777411  -1.2577794
   1.1379876   0.2939975   0.26858163 -0.36551866  0.6111065  -0.2827438
  -0.10195993 -0.44476694 -0.6343034  -1.5563715  -2.075575   -2.6288292
   1.6396052   0.45393434 -0.40322024  0.17557165 -0.34999278  0.43776447
  -0.42949954 -1.3719515  -0.70812094  0.52499413  0.59308547 -0.2140188
   0.46110788  0.2508945 ]]
tensor([[-0.7199]], device='cuda:0')
tensor([-79.5126], device='cuda:0')
[[ 0.07906201  1.         -0.08293784 -1.          0.7791417   1.
   1.          0.27537555  0.79398644  0.5335053   1.          0.36317116
  -0.6226528  -0.03318336  0.7976863  -1.          1.         -0.25947368
  -0.92329156  0.36749226 -1.          0.6012655  -0.33593607  1.
   0.17069107 -0.8102963   0.61052924  1.         -1.         -1.
   1.          0.2939975   0.26858163 -0.36551866  0.6111065  -0.2827438
  -0.10195993 -0.44476694 -0.6343034  -1.         -1.         -1.
   1.          0.45393434 -0.40322024  0.17557165 -0.34999278  0.43776447
  -0.42949954 -1.         -0.70812094  0.52499413  0.59308547 -0.2140188
   0.46110788  0.2508945 ]]
[[-0.21407817  0.53575337  0.38490474 ...  0.18654081  0.9806306
   0.05971763]]
[0.11666749]
[False]
[{'discount': 1.0, 'TimeLimit.truncated': False}]
0
False
tensor([[-0.2946,  0.6053, -0.2534,  ...,  0.2401,  0.7247,  0.6459]],
       device='cuda:0')
tensor([-1.2566], device='cuda:0')
<stable_baselines3.ppo.ppo.PPO object at 0x7f9bc1cc8850>
50000
<__main__.SummaryWriterCallback object at 0x7f9bc1cc8cd0>
1
first_run
True
False
0
<stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f9bc1cc8910>
<stable_baselines3.common.buffers.RolloutBuffer object at 0x7f9bc1cc89d0>
2048
199
tensor([[-0.3586,  0.4300,  0.1385,  ..., -0.0921,  0.9630, -0.2532]],
       device='cuda:0')
[[ 0.65218014  1.0057532  -1.3496076   2.1945257  -0.14658184 -1.2592064
   0.21625128 -1.3439721  -0.6948265   1.5388526   0.02392304  0.22700737
   3.3147652   0.22637337 -0.74947685  0.8589844  -0.5463873  -0.97350115
   0.75206894  0.11367159 -0.10606924 -0.6641649  -1.3618919   0.46420375
  -0.633874    0.36739412 -0.04310698  0.6989078   0.25999534  0.64366126
   0.9685783  -0.82540226 -0.843033    0.22927131  0.428255   -0.48222262
  -0.361001   -0.19415884  2.2570822   0.17712307  1.5972149  -0.3917643
   0.3109011  -1.1270229   0.91125196 -0.62311447 -0.4582218  -0.24163595
   0.76704353 -0.9264802   1.7862939  -2.1406817  -0.05717746  1.494653
  -0.37924105 -0.15721211]]
tensor([[-0.2066]], device='cuda:0')
tensor([-80.3932], device='cuda:0')
[[ 0.65218014  1.         -1.          1.         -0.14658184 -1.
   0.21625128 -1.         -0.6948265   1.          0.02392304  0.22700737
   1.          0.22637337 -0.74947685  0.8589844  -0.5463873  -0.97350115
   0.75206894  0.11367159 -0.10606924 -0.6641649  -1.          0.46420375
  -0.633874    0.36739412 -0.04310698  0.6989078   0.25999534  0.64366126
   0.9685783  -0.82540226 -0.843033    0.22927131  0.428255   -0.48222262
  -0.361001   -0.19415884  1.          0.17712307  1.         -0.3917643
   0.3109011  -1.          0.91125196 -0.62311447 -0.4582218  -0.24163595
   0.76704353 -0.9264802   1.         -1.         -0.05717746  1.
  -0.37924105 -0.15721211]]
[[-0.22088076  0.61696863  0.08244787 ...  0.2933647   0.93661314
  -0.19155416]]
[0.09126522]
[False]
[{'discount': 1.0, 'TimeLimit.truncated': False}]
0
False
tensor([[-0.1411,  0.1897,  0.4514,  ..., -0.1630,  0.9818,  0.0976]],
       device='cuda:0')
tensor([-0.6630], device='cuda:0')
^CTraceback (most recent call last):
  File "/home/elmo/Documents/project/LLM_CD/mannual_train.py", line 49, in <module>
    model.learn(total_timesteps=50000, tb_log_name="first_run", callback=SummaryWriterCallback())
  File "/home/elmo/.local/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 315, in learn
    return super().learn(
  File "/home/elmo/.local/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 277, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "/home/elmo/.local/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 194, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
  File "/home/elmo/.local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 206, in step
    return self.step_wait()
  File "/home/elmo/.local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
  File "/home/elmo/.local/lib/python3.10/site-packages/stable_baselines3/common/monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
  File "/home/elmo/Documents/project/LLM_CD/DMC_Gym.py", line 98, in step
    timestep = self._env.step(action)
  File "/home/elmo/.local/lib/python3.10/site-packages/dm_control/composer/environment.py", line 412, in step
    self._observation_updater.update()
  File "/home/elmo/.local/lib/python3.10/site-packages/dm_control/composer/observation/updater.py", line 295, in update
    enabled.observation_callable())
  File "/home/elmo/.local/lib/python3.10/site-packages/dm_control/composer/observation/observable/mjcf.py", line 266, in get_observation
    pixels = physics.render(
  File "/home/elmo/.local/lib/python3.10/site-packages/dm_control/mujoco/engine.py", line 229, in render
    image = camera.render(
  File "/home/elmo/.local/lib/python3.10/site-packages/dm_control/mujoco/engine.py", line 891, in render
    ctx.call(self._render_on_gl_thread, depth=depth, overlays=overlays)
  File "/home/elmo/.local/lib/python3.10/site-packages/dm_control/_render/executor/render_executor.py", line 138, in call
    return func(*args, **kwargs)
  File "/home/elmo/.local/lib/python3.10/site-packages/dm_control/mujoco/engine.py", line 813, in _render_on_gl_thread
    mujoco.mjr_readPixels(self._rgb_buffer if not depth else None,
KeyboardInterrupt

(LLM_CD) elmo@ElmoPA:~/Documents/project/LLM_CD$ python3 mannual_train.py 
pygame 2.5.2 (SDL 2.28.2, Python 3.10.12)
Hello from the pygame community. https://www.pygame.org/contribute.html
(12456,)
(12456,)
(56,)
(56,)
Using cuda device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Logging to ./logs/first_run_7
self <stable_baselines3.ppo.ppo.PPO object at 0x7fcaca3c48b0>
total_timesteps 50000
callback <__main__.SummaryWriterCallback object at 0x7fcaca3c4d30>
log_interval 1
tb_log_name first_run
reset_num_timesteps True
progress_bar False
iteration 0
env <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7fcaca3c4970>
rollout_buffer <stable_baselines3.common.buffers.RolloutBuffer object at 0x7fcaca3c4a30>
n_rollout_steps 2048
n_steps 99
obs_tensor tensor([[ 0.1799,  0.5393, -0.3169,  ..., -0.0735,  0.9358, -0.3449]],
       device='cuda:0')
actions [[ 1.50939560e+00  8.14660072e-01 -7.97095478e-01  8.29715371e-01
   4.43147123e-01  7.88729489e-01 -4.64843631e-01  1.18183649e+00
   1.78025329e+00  2.33751154e+00  2.43056998e-01  3.02892225e-03
   9.72872853e-01 -1.04900455e+00 -1.03502178e+00 -2.92826474e-01
   9.46332276e-01 -6.66973293e-02 -1.23693097e+00  2.41189197e-01
   1.31929231e+00  6.99421465e-01  5.05671604e-03 -1.18161134e-01
  -1.67798054e+00 -1.11150217e+00  3.49522978e-01 -3.30039561e-02
  -7.94779539e-01  9.15272892e-01  9.19634700e-01  3.68318200e-01
  -1.68048233e-01  1.40633774e+00 -5.10893941e-01  1.86676428e-01
   1.21274903e-01  3.03745449e-01 -8.52409303e-02  9.52647209e-01
  -1.27341878e+00 -2.56026506e+00 -1.04684794e+00 -1.01886950e-01
   1.35277832e+00  6.95055902e-01 -1.36431330e-03  1.53286289e-03
  -5.77008843e-01  6.49143577e-01 -1.26862049e+00  1.36986852e+00
   8.96388710e-01  3.96119058e-01 -8.43240023e-01 -8.96352008e-02]]
values tensor([[-0.5012]], device='cuda:0')
log_probs tensor([-76.8508], device='cuda:0')
clipped_actions [[ 1.          0.8146601  -0.7970955   0.8297154   0.44314712  0.7887295
  -0.46484363  1.          1.          1.          0.243057    0.00302892
   0.97287285 -1.         -1.         -0.29282647  0.9463323  -0.06669733
  -1.          0.2411892   1.          0.69942147  0.00505672 -0.11816113
  -1.         -1.          0.34952298 -0.03300396 -0.79477954  0.9152729
   0.9196347   0.3683182  -0.16804823  1.         -0.51089394  0.18667643
   0.1212749   0.30374545 -0.08524093  0.9526472  -1.         -1.
  -1.         -0.10188695  1.          0.6950559  -0.00136431  0.00153286
  -0.57700884  0.6491436  -1.          1.          0.8963887   0.39611906
  -0.84324    -0.0896352 ]]
new_obs [[ 0.35457012  0.62726885  0.11708229 ... -0.14496568  0.9746681
   0.17031454]]
rewards [0.]
dones [False]
infos [{'discount': 1.0, 'TimeLimit.truncated': False}]
idx 0
done False
terminal_obs tensor([[-0.1857,  0.3929,  0.3900,  ..., -0.5564,  0.3966, -0.7302]],
       device='cuda:0')
terminal_value tensor([-0.1077], device='cuda:0')